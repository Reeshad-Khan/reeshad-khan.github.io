<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="description" content="Reeshad Khan — Efficient AI (EdgeAI) & Autonomous Systems Perception: BEV, radar–vision fusion, RAW-to-task co-design, real-time deployment." />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Reeshad Khan — Efficient AI & Autonomous Perception</title>
  <style>
    /* Basic Reset */
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
      background-color: #f4f4f9;
      color: #333;
      line-height: 1.6;
      margin: 0;
      padding-bottom: 80px; /* space for footer */
    }
    header {
      background: #0056b3;
      color: #fff;
      padding: 40px 20px;
      text-align: center;
    }
    header h1 { margin-bottom: 10px; font-size: 2.2rem; font-weight: 600; }
    header p { font-size: 1.1rem; margin-bottom: 10px; }

    /* Nav */
    nav { background-color: #333; overflow: hidden; }
    nav ul {
      list-style-type: none; display: flex; justify-content: center; padding: 0;
    }
    nav ul li { margin: 0 15px; }
    nav a {
      display: block; padding: 14px 20px; color: #fff; text-decoration: none; font-weight: 500;
    }
    nav a:hover { background-color: #444; transition: 0.3s; }

    /* Layout */
    main { max-width: 1100px; margin: 20px auto; padding: 0 20px; }
    section { margin: 30px 0; }
    section h2 { font-size: 1.8rem; margin-bottom: 10px; color: #0056b3; }
    section h3 { font-size: 1.2rem; margin: 10px 0 6px; }
    section p, section ul, section ol { font-size: 1rem; margin-bottom: 12px; }
    ul { margin-left: 20px; list-style-type: disc; }
    ol { margin-left: 20px; list-style-type: decimal; }

    /* About Section Layout */
    .about-container {
      display: flex;
      align-items: flex-start;
      gap: 20px;
    }
    .profile-photo {
      max-width: 180px;
      border-radius: 10%;
      margin: 0;
      box-shadow: 0 0 6px rgba(0,0,0,0.1);
    }
    .about-text { flex: 1; }

    .pill {
      display: inline-block; padding: 6px 10px; margin: 6px 6px 0 0;
      background:#e8f1fb; color:#0056b3; border-radius:999px; font-size: 0.9rem; border:1px solid #c9defa;
    }
    .card {
      background: #fff; border-radius: 12px; padding: 16px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.06); margin: 14px 0;
    }
    .grid {
      display: grid; grid-template-columns: repeat(12, 1fr); gap: 16px;
    }
    .col-12 { grid-column: span 12; }
    .col-6 { grid-column: span 6; }
    .col-4 { grid-column: span 4; }

    .btn {
      display:inline-block; padding:10px 14px; background:#0056b3; color:#fff; border-radius:6px; text-decoration:none; font-weight:600;
    }
    .btn.outline { background:#fff; color:#0056b3; border:1px solid #0056b3; }

    footer {
      width: 100%; background-color: #333; color: #fff;
      position: fixed; bottom: 0; left: 0; padding: 15px 0; text-align: center;
    }
    footer p { margin: 0; font-size: 0.9rem; }
    a { color: #0056b3; text-decoration: none; }
    a:hover { text-decoration: underline; }

    /* Responsive */
    @media (max-width: 900px) {
      .col-6, .col-4 { grid-column: span 12; }
    }
    @media (max-width: 768px) {
      header h1 { font-size: 1.8rem; }
      nav ul { flex-direction: column; }
      nav ul li { margin: 5px 0; }
      .about-container { flex-direction: column; align-items: center; text-align: center; }
      .about-text { text-align: left; }
    }
  </style>
</head>
<body>
  <!-- Header -->
  <header>
    <h1>Reeshad Khan</h1>
    <p>Efficient AI (EdgeAI) & Autonomous Systems Perception — BEV • Radar–Vision Fusion • RAW-to-Task Co-Design</p>
    <p>
      <a class="btn" href="https://github.com/Reeshad-Khan" target="_blank" rel="noopener">GitHub</a>
      <a class="btn outline" href="https://scholar.google.com/citations?user=D3rO3W4AAAAJ" target="_blank" rel="noopener">Google Scholar</a>
    </p>
  </header>

  <!-- Nav -->
  <nav>
    <ul>
      <li><a href="#about">About</a></li>
      <li><a href="#focus">Research Focus</a></li>
      <li><a href="#projects">Flagship Projects</a></li>
      <li><a href="#publications">Publications</a></li>
      <li><a href="#skills">Skills</a></li>
      <li><a href="#contact">Contact</a></li>
    </ul>
  </nav>

  <!-- Main -->
  <main>
    <!-- About -->
    <section id="about">
      <h2>About Me</h2>
      <div class="about-container">
        <img src="profile.jpg" alt="Profile Photo" class="profile-photo" />
        <div class="about-text">
          <p class="card">
            I build <strong>efficient perception systems</strong> for autonomy that run <strong>real-time on edge hardware</strong>.
            My work spans <strong>camera-only BEV</strong> (TinyBEV), <strong>radar–vision fusion</strong> for adverse weather,
            <strong>sensor–optics–model co-design</strong> (RAW-to-task) for robustness, and <strong>evaluation frameworks</strong>
            for 3D reconstruction (4DCF). I care about <em>latency, reliability, and deployment</em>—profiling, pruning,
            quantization, TensorRT, and mixed precision to hit FPS targets without sacrificing safety.
          </p>
          <div>
            <span class="pill">Real-Time BEV</span>
            <span class="pill">EdgeAI</span>
            <span class="pill">Radar–Vision Fusion</span>
            <span class="pill">RAW-to-Task Co-Design</span>
            <span class="pill">Embedded Deployment</span>
            <span class="pill">3D Perception</span>
          </div>
        </div>
      </div>
    </section>

    <!-- Research Focus -->
    <section id="focus">
      <h2>Research Focus</h2>
      <div class="grid">
        <div class="col-6 card">
          <h3>Efficient AI / EdgeAI</h3>
          <ul>
            <li>Model compression (pruning, quantization), TensorRT, AMP</li>
            <li>Throughput-driven design for NVIDIA Orin/Jetson, RTX/Datacenter GPUs</li>
            <li>Profiling: kernel hotspots, memory scheduling, batch-1 latency</li>
          </ul>
        </div>
        <div class="col-6 card">
          <h3>Autonomous Perception</h3>
          <ul>
            <li>Camera-only <strong>BEV</strong> perception (detection, mapping, forecasting, planning)</li>
            <li><strong>Radar–Vision fusion</strong> for fog/rain/low-light robustness</li>
            <li><strong>Sensor–optics co-design</strong> (RAW-to-task) for semantics under noise/quantization</li>
          </ul>
        </div>
      </div>
    </section>

    <!-- Projects -->
    <section id="projects">
      <h2>Flagship Projects</h2>

      <article class="card">
        <h3>TinyBEV — Cross-Modal Distillation for Camera-Only BEV (ICCV 2025 WDFM)</h3>
        <p>
          Lightweight BEV model distilled from UniAD for <strong>real-time, camera-only</strong> multi-task autonomy:
          detection, mapping, forecasting, and planning. Designed for <strong>embedded deployment</strong> (EdgeAI).
        </p>
        <ul>
          <li>Knowledge distillation to compress multi-modal teacher → compact student</li>
          <li>Latency-aware training; on-device optimizations to meet FPS targets</li>
        </ul>
        <p><a href="#" aria-disabled="true">Paper (soon)</a> · <a href="https://github.com/Reeshad-Khan" target="_blank" rel="noopener">Code & demos</a></p>
      </article>

      <article class="card">
        <h3>Learning to Sense for Driving — RAW-to-Task Optics–Sensor–Model Co-Design (WACV 2026 under review)</h3>
        <p>
          End-to-end <strong>co-design</strong> of cellphone-scale optics, learnable CFA, Poisson–Gaussian noise, and
          quantization with a compact segmentation head. Improves mIoU and boundary accuracy under low-light,
          blur, and reduced bit-depth—<strong>robust semantics with deployment-grade runtime</strong>.
        </p>
        <ul>
          <li>Exposure control + differentiable optics; straight-through quantization</li>
          <li>Mixed precision, ablations, and Pareto (accuracy vs. latency) analysis</li>
        </ul>
        <p><a href="#" aria-disabled="true">Preprint (under review)</a></p>
      </article>

      <article class="card">
        <h3>Radar–Vision Fusion for Adverse Conditions (WACV 2026 project)</h3>
        <p>
          Modular fusion (early/late/attention) to maintain perception quality in rain, fog, and low light.
          Targets <strong>real-time inference</strong> and <strong>embedded deployment</strong> with ablation-ready components.
        </p>
        <ul>
          <li>nuScenes-based pipelines; attention-weighted sensor reliability</li>
          <li>Profiling, visualization, and safety-critical metrics tracking</li>
        </ul>
        <p><a href="#" aria-disabled="true">Tech report (in prep)</a></p>
      </article>

      <article class="card">
        <h3>4DCF — Robustness Evaluation for 3D Reconstruction (ISVC 2025 under review)</h3>
        <p>
          A unified robustness suite for 3D reconstruction: <strong>Spatial Smoothness</strong>, <strong>Scale Stability</strong>,
          <strong>Perturbation Robustness</strong>, and <strong>Temporal Consistency</strong>, with radar-chart diagnostics to
          expose failure modes beyond Chamfer/PSNR.
        </p>
        <p><a href="#" aria-disabled="true">Preprint (under review)</a></p>
      </article>

      <article class="card">
        <h3>Semantic Scene Understanding for Autonomous Systems</h3>
        <p>
          Real-time panoptic perception and 3D reconstruction across diverse environments with deployment-minded
          training (mixed precision, memory optimization, structured pruning).
        </p>
      </article>

      <p style="margin-top:8px; color:#555;">
        <em>Earlier work:</em> unsupervised MRI denoising and reconstruction (VISAPP 2025; IEEE Access)—useful for
        technique development, but current focus is autonomy & EdgeAI.
      </p>
    </section>

    <!-- Publications -->
    <section id="publications">
      <h2>Selected Publications</h2>
      <ol class="card">
        <li><strong>TinyBEV</strong>: Cross-Modal Knowledge Distillation for Efficient Multi-Task BEV Perception and Planning. <em>ICCV WDFM Workshop</em>, 2025.</li>
        <li><strong>Learning to Sense for Driving</strong>: Joint Optics–Sensor–Model Co-Design for Semantic Segmentation. <em>WACV 2026</em>, under review.</li>
        <li><strong>4DCF</strong>: A 4D Consistency Field for Robust Evaluation of 3D Scene Reconstruction. <em>ISVC 2025</em>, under review.</li>
        <li><strong>From Noise Estimation to Restoration</strong>. <em>VISAPP 2025</em>.</li>
        <li><strong>Learning from Oversampling for MRI Reconstruction</strong>. <em>IEEE Access</em>, 2024.</li>
      </ol>
      <p>
        Full list on <a href="https://scholar.google.com/citations?user=D3rO3W4AAAAJ" target="_blank" rel="noopener">Google Scholar</a>.
      </p>
    </section>

    <!-- Skills -->
    <section id="skills">
      <h2>Skills</h2>
      <div class="grid">
        <div class="col-4 card">
          <h3>Perception</h3>
          <ul>
            <li>Detection, segmentation, panoptic, BEV</li>
            <li>3D reconstruction & evaluation (4DCF)</li>
          </ul>
        </div>
        <div class="col-4 card">
          <h3>EdgeAI</h3>
          <ul>
            <li>Pruning, quantization, TensorRT, AMP</li>
            <li>Kernel/memory profiling, batch-1 latency</li>
          </ul>
        </div>
        <div class="col-4 card">
          <h3>Stacks & Tools</h3>
          <ul>
            <li>PyTorch, TensorFlow, Detectron2, OpenCV</li>
            <li>CUDA, Docker, CI/CD, HPC clusters</li>
          </ul>
        </div>
      </div>
    </section>

    <!-- Contact -->
    <section id="contact">
      <h2>Contact</h2>
      <p class="card">
        <strong>Email:</strong> <a href="mailto:rk010@uark.edu">rk010@uark.edu</a><br />
        <strong>LinkedIn:</strong> <a href="https://www.linkedin.com/in/reeshad-khan-a50207106/" target="_blank" rel="noopener">linkedin.com/in/reeshad-khan-a50207106</a><br />
        <strong>GitHub:</strong> <a href="https://github.com/Reeshad-Khan" target="_blank" rel="noopener">github.com/Reeshad-Khan</a>
      </p>
    </section>
  </main>

  <!-- Footer -->
  <footer>
    <p>&copy; <script>document.write(new Date().getFullYear());</script> Reeshad Khan — Efficient AI & Autonomous Perception</p>
  </footer>
</body>
</html>
